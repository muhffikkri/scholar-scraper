# Google Scholar Scraper

Aplikasi Python untuk scraping otomatis data publikasi dosen dari Google Scholar dengan GUI dan integrasi Google Sheets.

## üöÄ Quick Start

```bash
# Clone project
git clone [repository-url]
cd scholar-scraper

# Setup & Run (Windows)
setup.bat

# Atau manual:
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python main.py --gui
```

## üìã Requirements

- Python 3.8+
- Google Chrome
- ChromeDriver (auto-install via selenium)

## üéØ Features

‚úÖ **Dual Mode**: GUI & CLI  
‚úÖ **Smart Scraping**: Auto-parse venue, citations, authors  
‚úÖ **Per-Year Citations**: Track cited-by data per year (customizable range)  
‚úÖ **CAPTCHA Handling**: Manual CAPTCHA solving with auto-wait  
‚úÖ **Comprehensive Logging**: Track success, failures, and CAPTCHA blocks  
‚úÖ **Multi-Format Output**: Excel, CSV, DOCX  
‚úÖ **Google Sheets Integration**: Direct upload via Apps Script  
‚úÖ **Batch & Single**: Scraping multiple or individual dosen  
‚úÖ **Real-time Monitoring**: Progress tracking with detailed logs

## üìñ Usage

### Mode 1: GUI (Recommended)

```bash
python main.py --gui
```

**Tab Scraping:**

- Batch: Upload CSV/TXT file with dosen names
- Single: Input one dosen name manually
- Config: Headless mode, timeout settings
- Output: Auto-saved to `output/` folder

**Tab Upload:**

- Select Excel file
- Enter Google Sheets URL
- One-click upload

### Mode 2: CLI

```bash
python main.py
```

Edit `main.py` untuk konfigurasi:

```python
INPUT_FILE_PATH = "input/daftar_dosen.csv"
HEADLESS_MODE = False
WAIT_TIME = 10
```

## üìÅ Project Structure

```
scholar-scraper/
‚îú‚îÄ‚îÄ main.py                 # Entry point (GUI/CLI)
‚îú‚îÄ‚îÄ setup.bat               # Auto setup script
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ .env                    # Configuration (create from .env.example)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core_logic/         # Scraping logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_handler.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îî‚îÄ‚îÄ gui/                # GUI components
‚îÇ       ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ input/                  # Input files (CSV/TXT)
‚îî‚îÄ‚îÄ output/                 # Results (auto-created)
```

## ‚öôÔ∏è Configuration (.env)

Copy `.env.example` to `.env`:

```env
# Apps Script URL (required for Google Sheets upload)
APPS_SCRIPT_URL=https://script.google.com/macros/s/YOUR_ID/exec

# Optional settings
DEFAULT_SHEET_NAME=Publikasi Dosen
DEFAULT_WAIT_TIME=10
DEFAULT_HEADLESS_MODE=false
OUTPUT_DIRECTORY=output
```

## üì§ Google Sheets Setup

### 1. Deploy Apps Script

1. Buka https://script.google.com
2. New Project ‚Üí Copy code dari `apps-script-web-app.gs`
3. Deploy ‚Üí New deployment:
   - Type: **Web app**
   - Execute as: **Me**
   - Who has access: **Anyone** ‚ö†Ô∏è PENTING!
4. Copy Web app URL
5. Paste ke `.env` ‚Üí `APPS_SCRIPT_URL=...`

### 2. Upload Data

1. GUI ‚Üí Tab Upload
2. Select Excel file (or use last scraped)
3. Enter Spreadsheet URL:
   ```
   https://docs.google.com/spreadsheets/d/SPREADSHEET_ID/edit
   ```
4. Enter Sheet Name (auto-created if not exists)
5. Click Upload

## üìä Output Columns

| Column       | Description             |
| ------------ | ----------------------- |
| Nama Dosen   | Dosen name              |
| Judul        | Publication title       |
| Penulis      | Authors list            |
| Journal_Name | Journal/conference name |
| Volume       | Volume number           |
| Issue        | Issue number            |
| Pages        | Page range              |
| Publisher    | Publisher name          |
| Tahun        | Year                    |
| Sitasi       | Citation count          |
| Link         | Google Scholar URL      |

## üîß Advanced

### Input File Format

**CSV:**

```csv
Nama
Dr. John Doe, M.Kom
Prof. Jane Smith, Ph.D
```

**TXT:**

```
Dr. John Doe, M.Kom
Prof. Jane Smith, Ph.D
```

### Output Files

```
output/
‚îú‚îÄ‚îÄ publikasi_daftar_dosen_20241022_143000.xlsx
‚îú‚îÄ‚îÄ publikasi_daftar_dosen_20241022_143000.csv
‚îî‚îÄ‚îÄ publikasi_daftar_dosen_20241022_143000_summary.docx
```

Single scraping:

```
publikasi_John_Doe_20241022_143000.xlsx
```

## üêõ Troubleshooting

### Error 403 Forbidden (Upload)

**Cause:** Apps Script permission not set to "Anyone"

**Fix:**

1. script.google.com ‚Üí Your project
2. Deploy ‚Üí Manage deployments ‚Üí Edit
3. **Who has access** = **Anyone** (not "Anyone with Google account")
4. Deploy ‚Üí Copy new URL
5. Update `.env` ‚Üí Restart app

### ChromeDriver Error

```bash
pip install --upgrade selenium
```

### Log Not Visible (GUI)

- Resize window (drag borders)
- Scroll down in tab
- Check terminal for backend logs

### Slow Scraping

- Enable headless mode (checkbox in GUI)
- Reduce wait time (but may cause timeouts)
- Check internet connection

## üì¶ Dependencies

```
selenium>=4.15.0          # Web automation
beautifulsoup4>=4.12.0    # HTML parsing
pandas>=2.0.0             # Data manipulation
openpyxl>=3.1.0           # Excel files
python-docx>=1.0.0        # Word documents
requests>=2.31.0          # HTTP requests
python-dotenv>=1.0.0      # Environment variables
```

## üîí Security

- `.env` file is git-ignored (contains sensitive URLs)
- Apps Script URL acts as API key
- Only you can access your spreadsheets
- "Anyone" permission is safe (script runs with your credentials)

## üé® GUI Tips

- **Batch Scraping**: Use dropdown or browse to select CSV/TXT
- **Single Scraping**: Click radio button, enter name manually
- **Quick Upload**: After scraping, click "Use Last Result" in Upload tab
- **Headless Mode**: Faster, no browser window
- **Logs**: Real-time progress with timestamps

## üöß Known Limitations

- Google Scholar may rate-limit heavy scraping
- CAPTCHA may appear during intensive scraping (handled with manual solving)
- Requires exact dosen name (as appears on Google Scholar)
- ChromeDriver must match Chrome version (auto-handled by selenium)
- Network timeout on slow connections

## üîç Advanced Features

### CAPTCHA Handling

When CAPTCHA is detected, the script will:

1. Pause scraping and notify you
2. Wait for manual CAPTCHA solving (default: 5 minutes)
3. Auto-continue after CAPTCHA is solved
4. Log CAPTCHA blocks for retry later

See [CAPTCHA_GUIDE.md](CAPTCHA_GUIDE.md) for details.

### Comprehensive Logging

All scraping activities are logged in `logging/` folder:

- **Summary JSON**: Session overview with statistics
- **Detailed CSV**: Per-dosen results with timestamps
- **Failed Names**: List of failed scrapes with error types
- **CAPTCHA Blocks**: Separate list for CAPTCHA-blocked names

See [LOGGING_GUIDE.md](LOGGING_GUIDE.md) for details.

### Per-Year Citations

Track citations per year with customizable range:

- Set year range in GUI (From - To)
- Get separate columns: `2020_cited_by`, `2021_cited_by`, etc.
- Useful for tracking publication impact over time

## üìù License

For research and educational purposes. Respect Google Scholar's Terms of Service.

## ü§ù Contributing

Issues and pull requests welcome!

## üìû Support

- Check logs in GUI for errors
- Verify `.env` configuration
- Ensure Chrome is installed
- Test with single dosen first

---

**Quick Commands:**

```bash
# GUI Mode
python main.py --gui

# CLI Mode
python main.py

# Setup Everything
setup.bat

# Check Python
python --version

# Install Dependencies
pip install -r requirements.txt
```

---

Made with ‚ù§Ô∏è for academic research
