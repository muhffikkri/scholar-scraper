# Google Scholar Scraper

Aplikasi Python untuk scraping otomatis data publikasi dosen dari Google Scholar dengan GUI dan integrasi Google Sheets.

## ğŸš€ Quick Start

```bash
# Clone project
git clone [repository-url]
cd scholar-scraper

# Setup & Run (Windows)
setup.bat

# Atau manual:
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python main.py --gui
```

## ğŸ“‹ Requirements

- Python 3.8+
- Google Chrome
- ChromeDriver (auto-install via selenium)

## ğŸ¯ Features

âœ… **Dual Mode**: GUI & CLI  
âœ… **Smart Scraping**: Auto-parse venue, citations, authors  
âœ… **Multi-Format Output**: Excel, CSV, DOCX  
âœ… **Google Sheets Integration**: Direct upload via Apps Script  
âœ… **Batch & Single**: Scraping multiple or individual dosen  
âœ… **Real-time Logging**: Monitor progress  

## ğŸ“– Usage

### Mode 1: GUI (Recommended)

```bash
python main.py --gui
```

**Tab Scraping:**
- Batch: Upload CSV/TXT file with dosen names
- Single: Input one dosen name manually
- Config: Headless mode, timeout settings
- Output: Auto-saved to `output/` folder

**Tab Upload:**
- Select Excel file
- Enter Google Sheets URL
- One-click upload

### Mode 2: CLI

```bash
python main.py
```

Edit `main.py` untuk konfigurasi:
```python
INPUT_FILE_PATH = "input/daftar_dosen.csv"
HEADLESS_MODE = False
WAIT_TIME = 10
```

## ğŸ“ Project Structure

```
scholar-scraper/
â”œâ”€â”€ main.py                 # Entry point (GUI/CLI)
â”œâ”€â”€ setup.bat               # Auto setup script
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env                    # Configuration (create from .env.example)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core_logic/         # Scraping logic
â”‚   â”‚   â”œâ”€â”€ scraper.py
â”‚   â”‚   â”œâ”€â”€ file_handler.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â””â”€â”€ gui/                # GUI components
â”‚       â””â”€â”€ app.py
â”œâ”€â”€ input/                  # Input files (CSV/TXT)
â””â”€â”€ output/                 # Results (auto-created)
```

## âš™ï¸ Configuration (.env)

Copy `.env.example` to `.env`:

```env
# Apps Script URL (required for Google Sheets upload)
APPS_SCRIPT_URL=https://script.google.com/macros/s/YOUR_ID/exec

# Optional settings
DEFAULT_SHEET_NAME=Publikasi Dosen
DEFAULT_WAIT_TIME=10
DEFAULT_HEADLESS_MODE=false
OUTPUT_DIRECTORY=output
```

## ğŸ“¤ Google Sheets Setup

### 1. Deploy Apps Script

1. Buka https://script.google.com
2. New Project â†’ Copy code dari `apps-script-web-app.gs`
3. Deploy â†’ New deployment:
   - Type: **Web app**
   - Execute as: **Me**
   - Who has access: **Anyone** âš ï¸ PENTING!
4. Copy Web app URL
5. Paste ke `.env` â†’ `APPS_SCRIPT_URL=...`

### 2. Upload Data

1. GUI â†’ Tab Upload
2. Select Excel file (or use last scraped)
3. Enter Spreadsheet URL:
   ```
   https://docs.google.com/spreadsheets/d/SPREADSHEET_ID/edit
   ```
4. Enter Sheet Name (auto-created if not exists)
5. Click Upload

## ğŸ“Š Output Columns

| Column | Description |
|--------|-------------|
| Nama Dosen | Dosen name |
| Judul | Publication title |
| Penulis | Authors list |
| Journal_Name | Journal/conference name |
| Volume | Volume number |
| Issue | Issue number |
| Pages | Page range |
| Publisher | Publisher name |
| Tahun | Year |
| Sitasi | Citation count |
| Link | Google Scholar URL |

## ğŸ”§ Advanced

### Input File Format

**CSV:**
```csv
Nama
Dr. John Doe, M.Kom
Prof. Jane Smith, Ph.D
```

**TXT:**
```
Dr. John Doe, M.Kom
Prof. Jane Smith, Ph.D
```

### Output Files

```
output/
â”œâ”€â”€ publikasi_daftar_dosen_20241022_143000.xlsx
â”œâ”€â”€ publikasi_daftar_dosen_20241022_143000.csv
â””â”€â”€ publikasi_daftar_dosen_20241022_143000_summary.docx
```

Single scraping:
```
publikasi_John_Doe_20241022_143000.xlsx
```

## ğŸ› Troubleshooting

### Error 403 Forbidden (Upload)

**Cause:** Apps Script permission not set to "Anyone"

**Fix:**
1. script.google.com â†’ Your project
2. Deploy â†’ Manage deployments â†’ Edit
3. **Who has access** = **Anyone** (not "Anyone with Google account")
4. Deploy â†’ Copy new URL
5. Update `.env` â†’ Restart app

### ChromeDriver Error

```bash
pip install --upgrade selenium
```

### Log Not Visible (GUI)

- Resize window (drag borders)
- Scroll down in tab
- Check terminal for backend logs

### Slow Scraping

- Enable headless mode (checkbox in GUI)
- Reduce wait time (but may cause timeouts)
- Check internet connection

## ğŸ“¦ Dependencies

```
selenium>=4.15.0          # Web automation
beautifulsoup4>=4.12.0    # HTML parsing
pandas>=2.0.0             # Data manipulation
openpyxl>=3.1.0           # Excel files
python-docx>=1.0.0        # Word documents
requests>=2.31.0          # HTTP requests
python-dotenv>=1.0.0      # Environment variables
```

## ğŸ”’ Security

- `.env` file is git-ignored (contains sensitive URLs)
- Apps Script URL acts as API key
- Only you can access your spreadsheets
- "Anyone" permission is safe (script runs with your credentials)

## ğŸ¨ GUI Tips

- **Batch Scraping**: Use dropdown or browse to select CSV/TXT
- **Single Scraping**: Click radio button, enter name manually
- **Quick Upload**: After scraping, click "Use Last Result" in Upload tab
- **Headless Mode**: Faster, no browser window
- **Logs**: Real-time progress with timestamps

## ğŸš§ Known Limitations

- Google Scholar may rate-limit heavy scraping
- Requires exact dosen name (as appears on Google Scholar)
- ChromeDriver must match Chrome version (auto-handled by selenium)
- Network timeout on slow connections

## ğŸ“ License

For research and educational purposes. Respect Google Scholar's Terms of Service.

## ğŸ¤ Contributing

Issues and pull requests welcome!

## ğŸ“ Support

- Check logs in GUI for errors
- Verify `.env` configuration
- Ensure Chrome is installed
- Test with single dosen first

---

**Quick Commands:**

```bash
# GUI Mode
python main.py --gui

# CLI Mode
python main.py

# Setup Everything
setup.bat

# Check Python
python --version

# Install Dependencies
pip install -r requirements.txt
```

---

Made with â¤ï¸ for academic research
